\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[italian]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{tikz}
\usepackage{tkz-euclide}
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{enumitem}
\usepackage{scrextend}
\usepackage{mathtools}

\title{K-Nearest Neighbors}
\author{Lorenzo Arcioni}

\begin{document}
\input{my_definitions}

\maketitle

\begin{abstract}
    In questo articolo, presentiamo un'analisi approfondita dell'algoritmo K-Nearest Neighbors (KNN), 
    esaminandolo sia dal punto di vista teorico che pratico. L'algoritmo KNN è un metodo di 
    apprendimento supervisionato utilizzato per la classificazione e la regressione, basato sul 
    principio che oggetti simili sono vicini nello spazio delle caratteristiche. Iniziamo con una 
    descrizione dettagliata dei fondamenti teorici del KNN, compresa la definizione formale, 
    i criteri di scelta del parametro K e le metriche di distanza utilizzate per determinare la 
    vicinanza tra i dati. Successivamente, esploriamo le sue proprietà matematiche e discutiamo l'impatto 
    della dimensionalità dei dati e del rumore sulla sua performance. Attraverso un'analisi empirica, 
    confrontiamo l'efficacia del KNN con altri algoritmi di machine learning, utilizzando dataset 
    standard. Infine, esaminiamo le tecniche di ottimizzazione e miglioramento del KNN, come 
    la normalizzazione dei dati e l'uso di pesi nei vicini, per aumentare la precisione e l'efficienza 
    computazionale. Questo studio offre una visione completa del KNN, evidenziando i suoi punti di forza, 
    le sue limitazioni e le situazioni in cui è più adatto. 
\end{abstract}

\tableofcontents
\input{main.toc}

\input{Chapters/01_Introduzione.tex}
\input{Chapters/02_Fondamenti_teorici.tex}
\input{Chapters/03_Analisi_Teorica.tex}
\input{Chapters/04_Ottimizzazioni.tex}

\nocite{*}
\bibliographystyle{unsrt}
\bibliography{sample.bib}

\end{document}